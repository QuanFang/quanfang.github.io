<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0027)https://quanfang.github.io/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	
	<style>
    .tooltip {
      position: relative;
    }

    .tooltip .tooltiptext {
      visibility: hidden;
      width: 100px;
      background-color: white;
      color: #000;
      text-align: center;
      border-radius: 6px;
      padding: 5px 0;

      /* Position the tooltip */
      position: absolute;
      z-index: 1;
      top: -5px;
      left: 70%;
    }

    .tooltip:hover .tooltiptext {
      visibility: visible;
      text-align: center;
      font-size: 36px;
    }

    .tooltip .tooltiptext a {
      color: #000;
    }

.container, .container-sm, .container-md, .container-lg, .container-xl {
    max-width:800px;

}

.nav {
  display: -ms-flexbox;
  display: flex;
  -ms-flex-wrap: wrap;
  flex-wrap: wrap;
  padding-left: 0;
  margin-bottom: 0;
  list-style: none;
}

.nav-link {
  display: block;
  padding: 0.5rem 1rem;
}

.nav-link:hover, .nav-link:focus {
  text-decoration: none;
}

.nav-link.disabled {
  color: #868e96;
  pointer-events: none;
  cursor: default;
}

.nav-tabs {
  border-bottom: 1px solid #ddd;
}

.nav-tabs .nav-item {
  margin-bottom: -1px;
}

.nav-tabs .nav-link {
  border: 1px solid transparent;
  border-top-left-radius: 0.25rem;
  border-top-right-radius: 0.25rem;
}

.nav-tabs .nav-link:hover, .nav-tabs .nav-link:focus {
  border-color: #e9ecef #e9ecef #ddd;
}

.nav-tabs .nav-link.disabled {
  color: #868e96;
  background-color: transparent;
  border-color: transparent;
}

.nav-tabs .nav-link.active,
.nav-tabs .nav-item.show .nav-link {
  color: #495057;
  background-color: #fff;
  border-color: #ddd #ddd #fff;
}

.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-left-radius: 0;
  border-top-right-radius: 0;
}

.nav-pills .nav-link {
  border-radius: 0.25rem;
}

.nav-pills .nav-link.active,
.nav-pills .show > .nav-link {
  color: #fff;
  background-color: #4582ec;
}

.nav-fill > .nav-link,
.nav-fill .nav-item {
  -ms-flex: 1 1 auto;
  flex: 1 1 auto;
  text-align: center;
}

.nav-justified > .nav-link,
.nav-justified .nav-item {
  -ms-flex-preferred-size: 0;
  flex-basis: 0;
  -ms-flex-positive: 1;
  flex-grow: 1;
  text-align: center;
}

.tab-content > .tab-pane {
  display: none;
}

.tab-content > .active {
  display: block;
}

.navbar {
  position: relative;
  display: -ms-flexbox;
  display: flex;
  -ms-flex-wrap: wrap;
  flex-wrap: wrap;
  -ms-flex-align: center;
  align-items: center;
  -ms-flex-pack: justify;
  justify-content: space-between;
  padding: 0.5rem 1rem;
}

.navbar .container,
.navbar .container-fluid, .navbar .container-sm, .navbar .container-md, .navbar .container-lg, .navbar .container-xl {
  display: -ms-flexbox;
  display: flex;
  -ms-flex-wrap: wrap;
  flex-wrap: wrap;
  -ms-flex-align: center;
  align-items: center;
  -ms-flex-pack: justify;
  justify-content: space-between;
}

.navbar-brand {
  display: inline-block;
  padding-top: 0.300688rem;
  padding-bottom: 0.300688rem;
  margin-right: 1rem;
  font-size: 1.32875rem;
  line-height: inherit;
  white-space: nowrap;
}

.navbar-brand:hover, .navbar-brand:focus {
  text-decoration: none;
}

.navbar-nav {
  display: -ms-flexbox;
  display: flex;
  -ms-flex-direction: column;
  flex-direction: column;
  padding-left: 0;
  margin-bottom: 0;
  list-style: none;
}

.navbar-nav .nav-link {
  padding-right: 0;
  padding-left: 0;
}

.navbar-nav .dropdown-menu {
  position: static;
  float: none;
}

.navbar-text {
  display: inline-block;
  padding-top: 0.5rem;
  padding-bottom: 0.5rem;
}

.navbar-collapse {
  -ms-flex-preferred-size: 100%;
  flex-basis: 100%;
  -ms-flex-positive: 1;
  flex-grow: 1;
  -ms-flex-align: center;
  align-items: center;
}

.navbar-toggler {
  padding: 0.25rem 0.75rem;
  font-size: 1.32875rem;
  line-height: 1;
  background-color: transparent;
  border: 1px solid transparent;
  border-radius: 0.25rem;
}

.navbar-toggler:hover, .navbar-toggler:focus {
  text-decoration: none;
}

.navbar-toggler-icon {
  display: inline-block;
  width: 1.5em;
  height: 1.5em;
  vertical-align: middle;
  content: "";
  background: no-repeat center center;
  background-size: 100% 100%;
}

@media (max-width: 575.98px) {
  .navbar-expand-sm > .container,
  .navbar-expand-sm > .container-fluid, .navbar-expand-sm > .container-sm, .navbar-expand-sm > .container-md, .navbar-expand-sm > .container-lg, .navbar-expand-sm > .container-xl {
    padding-right: 0;
    padding-left: 0;
  }
}

@media (min-width: 576px) {
  .navbar-expand-sm {
    -ms-flex-flow: row nowrap;
    flex-flow: row nowrap;
    -ms-flex-pack: start;
    justify-content: flex-start;
  }
  .navbar-expand-sm .navbar-nav {
    -ms-flex-direction: row;
    flex-direction: row;
  }
  .navbar-expand-sm .navbar-nav .dropdown-menu {
    position: absolute;
  }
  .navbar-expand-sm .navbar-nav .nav-link {
    padding-right: 0.5rem;
    padding-left: 0.5rem;
  }
  .navbar-expand-sm > .container,
  .navbar-expand-sm > .container-fluid, .navbar-expand-sm > .container-sm, .navbar-expand-sm > .container-md, .navbar-expand-sm > .container-lg, .navbar-expand-sm > .container-xl {
    -ms-flex-wrap: nowrap;
    flex-wrap: nowrap;
  }
  .navbar-expand-sm .navbar-collapse {
    display: -ms-flexbox !important;
    display: flex !important;
    -ms-flex-preferred-size: auto;
    flex-basis: auto;
  }
  .navbar-expand-sm .navbar-toggler {
    display: none;
  }
}

@media (max-width: 767.98px) {
  .navbar-expand-md > .container,
  .navbar-expand-md > .container-fluid, .navbar-expand-md > .container-sm, .navbar-expand-md > .container-md, .navbar-expand-md > .container-lg, .navbar-expand-md > .container-xl {
    padding-right: 0;
    padding-left: 0;
  }
}

@media (min-width: 768px) {
  .navbar-expand-md {
    -ms-flex-flow: row nowrap;
    flex-flow: row nowrap;
    -ms-flex-pack: start;
    justify-content: flex-start;
  }
  .navbar-expand-md .navbar-nav {
    -ms-flex-direction: row;
    flex-direction: row;
  }
  .navbar-expand-md .navbar-nav .dropdown-menu {
    position: absolute;
  }
  .navbar-expand-md .navbar-nav .nav-link {
    padding-right: 0.5rem;
    padding-left: 0.5rem;
  }
  .navbar-expand-md > .container,
  .navbar-expand-md > .container-fluid, .navbar-expand-md > .container-sm, .navbar-expand-md > .container-md, .navbar-expand-md > .container-lg, .navbar-expand-md > .container-xl {
    -ms-flex-wrap: nowrap;
    flex-wrap: nowrap;
  }
  .navbar-expand-md .navbar-collapse {
    display: -ms-flexbox !important;
    display: flex !important;
    -ms-flex-preferred-size: auto;
    flex-basis: auto;
  }
  .navbar-expand-md .navbar-toggler {
    display: none;
  }
}

@media (max-width: 991.98px) {
  .navbar-expand-lg > .container,
  .navbar-expand-lg > .container-fluid, .navbar-expand-lg > .container-sm, .navbar-expand-lg > .container-md, .navbar-expand-lg > .container-lg, .navbar-expand-lg > .container-xl {
    padding-right: 0;
    padding-left: 0;
  }
}

@media (min-width: 992px) {
  .navbar-expand-lg {
    -ms-flex-flow: row nowrap;
    flex-flow: row nowrap;
    -ms-flex-pack: start;
    justify-content: flex-start;
  }
  .navbar-expand-lg .navbar-nav {
    -ms-flex-direction: row;
    flex-direction: row;
  }
  .navbar-expand-lg .navbar-nav .dropdown-menu {
    position: absolute;
  }
  .navbar-expand-lg .navbar-nav .nav-link {
    padding-right: 0.5rem;
    padding-left: 0.5rem;
  }
  .navbar-expand-lg > .container,
  .navbar-expand-lg > .container-fluid, .navbar-expand-lg > .container-sm, .navbar-expand-lg > .container-md, .navbar-expand-lg > .container-lg, .navbar-expand-lg > .container-xl {
    -ms-flex-wrap: nowrap;
    flex-wrap: nowrap;
  }
  .navbar-expand-lg .navbar-collapse {
    display: -ms-flexbox !important;
    display: flex !important;
    -ms-flex-preferred-size: auto;
    flex-basis: auto;
  }
  .navbar-expand-lg .navbar-toggler {
    display: none;
  }
}

@media (max-width: 1199.98px) {
  .navbar-expand-xl > .container,
  .navbar-expand-xl > .container-fluid, .navbar-expand-xl > .container-sm, .navbar-expand-xl > .container-md, .navbar-expand-xl > .container-lg, .navbar-expand-xl > .container-xl {
    padding-right: 0;
    padding-left: 0;
  }
}

@media (min-width: 1200px) {
  .navbar-expand-xl {
    -ms-flex-flow: row nowrap;
    flex-flow: row nowrap;
    -ms-flex-pack: start;
    justify-content: flex-start;
  }
  .navbar-expand-xl .navbar-nav {
    -ms-flex-direction: row;
    flex-direction: row;
  }
  .navbar-expand-xl .navbar-nav .dropdown-menu {
    position: absolute;
  }
  .navbar-expand-xl .navbar-nav .nav-link {
    padding-right: 0.5rem;
    padding-left: 0.5rem;
  }
  .navbar-expand-xl > .container,
  .navbar-expand-xl > .container-fluid, .navbar-expand-xl > .container-sm, .navbar-expand-xl > .container-md, .navbar-expand-xl > .container-lg, .navbar-expand-xl > .container-xl {
    -ms-flex-wrap: nowrap;
    flex-wrap: nowrap;
  }
  .navbar-expand-xl .navbar-collapse {
    display: -ms-flexbox !important;
    display: flex !important;
    -ms-flex-preferred-size: auto;
    flex-basis: auto;
  }
  .navbar-expand-xl .navbar-toggler {
    display: none;
  }
}

.navbar-expand {
  -ms-flex-flow: row nowrap;
  flex-flow: row nowrap;
  -ms-flex-pack: start;
  justify-content: flex-start;
}

.navbar-expand > .container,
.navbar-expand > .container-fluid, .navbar-expand > .container-sm, .navbar-expand > .container-md, .navbar-expand > .container-lg, .navbar-expand > .container-xl {
  padding-right: 0;
  padding-left: 0;
}

.navbar-expand .navbar-nav {
  -ms-flex-direction: row;
  flex-direction: row;
}

.navbar-expand .navbar-nav .dropdown-menu {
  position: absolute;
}

.navbar-expand .navbar-nav .nav-link {
  padding-right: 0.5rem;
  padding-left: 0.5rem;
}

.navbar-expand > .container,
.navbar-expand > .container-fluid, .navbar-expand > .container-sm, .navbar-expand > .container-md, .navbar-expand > .container-lg, .navbar-expand > .container-xl {
  -ms-flex-wrap: nowrap;
  flex-wrap: nowrap;
}

.navbar-expand .navbar-collapse {
  display: -ms-flexbox !important;
  display: flex !important;
  -ms-flex-preferred-size: auto;
  flex-basis: auto;
}

.navbar-expand .navbar-toggler {
  display: none;
}

.navbar-light .navbar-brand {
  color: #343a40;
}

.navbar-light .navbar-brand:hover, .navbar-light .navbar-brand:focus {
  color: #343a40;
}

.navbar-light .navbar-nav .nav-link {
  color: rgba(0, 0, 0, 0.5);
}

.navbar-light .navbar-nav .nav-link:hover, .navbar-light .navbar-nav .nav-link:focus {
  color: #343a40;
}

.navbar-light .navbar-nav .nav-link.disabled {
  color: rgba(0, 0, 0, 0.3);
}

.navbar-light .navbar-nav .show > .nav-link,
.navbar-light .navbar-nav .active > .nav-link,
.navbar-light .navbar-nav .nav-link.show,
.navbar-light .navbar-nav .nav-link.active {
  color: #343a40;
}

.navbar-light .navbar-toggler {
  color: rgba(0, 0, 0, 0.5);
  border-color: rgba(0, 0, 0, 0.1);
}

.navbar-light .navbar-toggler-icon {
  background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' width='30' height='30' viewBox='0 0 30 30'%3e%3cpath stroke='rgba%280, 0, 0, 0.5%29' stroke-linecap='round' stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e");
}

.navbar-light .navbar-text {
  color: rgba(0, 0, 0, 0.5);
}

.navbar-light .navbar-text a {
  color: #343a40;
}

.navbar-light .navbar-text a:hover, .navbar-light .navbar-text a:focus {
  color: #343a40;
}

.navbar-dark .navbar-brand {
  color: #fff;
}

.navbar-dark .navbar-brand:hover, .navbar-dark .navbar-brand:focus {
  color: #fff;
}

.navbar-dark .navbar-nav .nav-link {
  color: rgba(255, 255, 255, 0.6);
}

.navbar-dark .navbar-nav .nav-link:hover, .navbar-dark .navbar-nav .nav-link:focus {
  color: #fff;
}

.navbar-dark .navbar-nav .nav-link.disabled {
  color: rgba(255, 255, 255, 0.25);
}

.navbar-dark .navbar-nav .show > .nav-link,
.navbar-dark .navbar-nav .active > .nav-link,
.navbar-dark .navbar-nav .nav-link.show,
.navbar-dark .navbar-nav .nav-link.active {
  color: #fff;
}

.navbar-dark .navbar-toggler {
  color: rgba(255, 255, 255, 0.6);
  border-color: rgba(255, 255, 255, 0.1);
}

.navbar-dark .navbar-toggler-icon {
  background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' width='30' height='30' viewBox='0 0 30 30'%3e%3cpath stroke='rgba%28255, 255, 255, 0.6%29' stroke-linecap='round' stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/%3e%3c/svg%3e");
}

.navbar-dark .navbar-text {
  color: rgba(255, 255, 255, 0.6);
}

.navbar-dark .navbar-text a {
  color: #fff;
}

.navbar-dark .navbar-text a:hover, .navbar-dark .navbar-text a:focus {
  color: #fff;
}
    hr {
  margin-top: -0.5rem;
  margin-bottom: -0.5rem;
  border: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}


	
  </style>


		
	
		<title>Quan Fang</title>
			
    <!-- <link rel="icon" type="image/png" href="images/su_icon_1color.png"/> -->
    <link rel="icon" type="image/png" href="https://quanfang.github.io/Quan%20Fang_files/bupt.png">

		<!-- CSS -->
    <link href="./Quan Fang_files/css" rel="stylesheet">
    <link rel="stylesheet" href="./Quan Fang_files/style.css" type="text/css" media="screen">
    <link rel="stylesheet" href="./Quan Fang_files/jquery.popup.css" type="text/css">
<!--     <link rel="stylesheet" href="./Quan Fang_files/bootstrap.css">-->
<!--      <link rel="stylesheet" href="./Quan Fang_files/tooltip-viewport.css" type="text/css"> -->

	
		<!-- ENDS CSS -->

    <!-- Global site tag (gtag.js) -Google Analytics -->
      <script type="text/javascript" async="" src="./Quan Fang_files/analytics.js.下载"></script><script type="text/javascript" async="" src="./Quan Fang_files/js"></script><script type="text/javascript" async="" src="./Quan Fang_files/js(1)"></script><script async="" src="./Quan Fang_files/gtm.js.下载"></script><script type="text/javascript" async="" src="./Quan Fang_files/analytics.js(1).下载"></script><script type="text/javascript" async="" src="./Quan Fang_files/js(2)"></script><script type="text/javascript" async="" src="./Quan Fang_files/js(3)"></script><script async="" src="./Quan Fang_files/gtm.js(1).下载"></script><script async="" src="./Quan Fang_files/js(4)"></script>
      <script>
    window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

          gtag('config', 'UA-47054450-2');
      </script>
    <!-- End Global site tag (gtag.js) -Google Analytics -->

    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MQ25LJL');</script>
    <!-- End Google Tag Manager -->

<meta name="google-site-verification" content="yFaGSVx2QHEe4twIMJJPV-L-68UuI_FYVYqdTfL7oX4" />	

	</head>	

	<body>


 <nav class="navbar navbar-expand-lg navbar-light bg-light">
        <div class="container">
           <button aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#navbarSupportedContent" data-toggle="collapse" type="button">
              <span class="navbar-toggler-icon"></span>
           </button>
           <div class="collapse navbar-collapse" id="navbarSupportedContent">
              <ul class="navbar-nav mr-auto">
                 <li class="nav-item  active">
                    <a class="nav-link" href="https://quanfang.github.io/index.html">MKC Group</a>
                 </li>
                 <li class="nav-item">
                    <a class="nav-link" href="#publications">Publications</a>
                 </li>
                 <li class="nav-item">
                    <a class="nav-link" href="https://quanfang.github.io/index.html" target="_blank">People</a>
                 </li>
              </ul>
           </div>

        </div>
      <hr/>
     </nav>
 <hr/>
	<br/>
		
    <div class="section">
      <table id="personal">
        <tbody><tr>
          <td id="basic">
            <div>
              <br>
              <div class="tooltip" align="center">
                <h1>Quan Fang (方全)</h1>
                <!-- <span class="tooltiptext"><a href="https://en.wiktionary.org/wiki/%E6%88%BF" target="_blank">房</a> <a href="https://en.wiktionary.org/wiki/%E5%AF%AC" target="_blank">宽</a></span> -->
              </div>
              <br>
              <h2><b>Email</b>: qfang@bupt.edu.cn</h2>
            </div>
          </td>
        </tr>

        <tr>

          <td id="bio">
            <div>
	    <p>I am currently a Research Professor in School of Artificial Intelligence at <a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications</a> (BUPT). I am the leader of  the Multimedia Knowledge Computing Group.
              </p>
              <br>
              <p>
               Prior to that, I was an Associate Professor at the National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences. I received my Ph.D. degree in Pattern Recognition and Intelligent System from <a href="http://nlpr-web.ia.ac.cn/mmc/index.html">Mutimedia Computing Group (MMC)</a>, <a href="http://www.nlpr.ia.ac.cn/">National Laboratory of Pattern Recognition</a>, <a href="http://www.ia.cas.cn/">Institute of Automation Chinese Academy of Sciences</a>, advised by <a href="http://nlpr-web.ia.ac.cn/mmc/homepage/csxu.html">Prof. Changsheng Xu</a> and <a href="http://nlpr-web.ia.ac.cn/mmc/homepage/jtsang.html">Dr. Jitao Sang</a>. I received a BE degree from the Automation Department, of <a href="http://www.buaa.edu.cn/">Beihang University</a>. I was a research intern in <a href="http://csidm.sg/">China-Singapore Institute of Digital Media</a>, 2012-2013.
              </p>
              <br>
              I am also the Leader of the Zhuanzhi Group, where I work with my brilliant colleagues to build the <a href="https://www.zhuanzhi.ai/">Zhuanzhi.AI</a> system that enable people to find required knowledge effectively and efficiently!
              <br>
            <br>
                <h2>
                  <a href="https://scholar.google.com/citations?hl=en&amp;user=6zJlUNEAAAAJ">Google Scholar</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://teacher.bupt.edu.cn/fangquan/zh_CN/index.htm">个人中文主页</a>
<!--                   &nbsp;&nbsp;|&nbsp;&nbsp;
                 <a href="https://www.linkedin.com/in/quanfang/">LinkedIn</a>--> 
<!--                  &nbsp;&nbsp;|&nbsp;&nbsp;-->
<!--                  <a href="https://twitter.com/QuanFang">Twitter</a>-->
                </h2>
		       <br>
            <br>



【<b>研究生实习生招生</b>】<br>
招收计算机科学与技术专业方向的硕士（保研+统考，学硕+专硕）和博士生（学术博士+工程博士）。欢迎具有扎实数学或编程基础, 有志于多媒体知识计算方向，包括知识图谱/大型语言模型/应用机器学习/数据挖掘方法/跨媒体分析与推理等研究的同学联系我。
		    
非常欢迎对科研感兴趣的本科生或研究生，加入本实验室进行科研实习，请发送你的个人简历到我的邮箱（qfang@bupt.edu.cn）！
		    
            </div>

          </td>

          <td id="photo">
            <div>
              <!-- <img src="images/quan_fang.jpg"/> -->
              <a href="https://quanfang.github.io/images/quan_fang_hd.jpg"><img src="./Quan Fang_files/quan_fang.jpg"></a>
            </div>
          </td>

        </tr>

      </tbody></table>
    </div>

    <div id="info">
    <!-- <div class="section"> -->
        
          
<!--              <br>-->
<!--              <b>I will be joining the <a href="https://www.cs.cornell.edu/">Department of Computer Science</a> at <a href="https://www.cornell.edu/">Cornell University</a> in Fall 2024.</b>-->
<!--          -->
        
    </div>


    <div id="info">
    <div class="section">
      <h1>Research</h1>
      <!-- <br/> -->
    Multimedia Knowledge Computing, including Multimodal Data Mining, Knowledge Graph Construction and Reasoning, Large language Model.
    </div>
    </div>



    <div id="info">

      <div class="section">
        <h1>News</h1><br>

        <ul>
			<li>One paper on "Cross-Modal Attention Network with Dual Graph Learning in Multimodal Recommendation" is accepted by TOMM 2026.</li>
			<li>One paper on "NOTAM-Evolve: A Knowledge-Guided Self-Evolving Optimization Framework with LLMs for NOTAM Interpretation" is accepted by AAAI 2026.</li>
			<li>One paper on "Knots: A Large-Scale Multi-Agent Enhanced Expert-Annotated Dataset and LLM Prompt Optimization for NOTAM Semantic Parsing" is accepted by Advanced Engineering Informatics.</li>
			<li>One paper on "Metapath-enhanced Language Model Pretraining on Text-Attributed Heterogeneous Graphs" is accepted by ACM TOMM 2025.</li>
          <li>One paper on "Contrastive Multi-Modal Knowledge Graph Representation Learning" is accepted by IEEE TKDE.</li>
<!--          <li>We are organizing <a href="https://sites.google.com/usc.edu/egg-rss-2023">Workshop on Environment Generation for Generalizable Robots (EGG)</a> at <a href="https://roboticsconference.org/">RSS 2023</a>.</li>-->
<!--          <li>I am honored to have received the CRA/NSF <a href="https://cccblog.org/2021/07/22/announcing-the-2021-computing-innovation-fellows/">Computing Innovation Fellowship</a>.</li>-->
<!--          <li>I started a Postdoc with <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a> at the Berkeley AI Research (BAIR) Lab.</li>-->
<!--          <li>We are organizing <a href="https://rssvlrr.github.io/">Workshop on Visual Learning and Reasoning for Robotics</a> at <a href="https://roboticsconference.org/">RSS 2021</a>.</li>-->
<!--          &lt;!&ndash; <li>We are organizing <a href="https://sites.google.com/view/iros2020dresr">Tutorial on Deep Representation and Estimation of State for Robotics</a> at <a href="https://sites.google.com/view/iros2020dresr">IROS 2020</a>.</li> &ndash;&gt;-->
          <!-- <li>We are organizing <a href="https://rss2020vlrrm.github.io/">Workshop on Visual Learning and Reasoning for Robotic Manipulation</a> at <a href="https://roboticsconference.org/">RSS 2020</a>.</li> -->
          <!-- <li>New <a href="http://ai.stanford.edu/blog/cavin/">SAIL Blog Post</a> about our recent work on Sequential Problem Solving by Hierarchical Planning in Latent Spaces.</li> -->
          <!-- <li>We released <a href="https://github.com/StanfordVL/robovat/">RoboVat</a>: A unified toolkit for simulated and real-world robotic task environments.</li> -->
        </ul>
      </div>

<!--      <div class="section">-->
<!--        <h1>Preprints</h1><br>-->
<!--        <table id="publications">-->

<!--          <tbody><tr>-->
<!--            <td id="publications-image">-->
<!--              <img src="./Kuan Fang_files/grif.png">-->
<!--            </td>-->
<!--            <td id="publications-info">-->
<!--              <p>-->
<!--                <span id="paper">-->
<!--                  Goal Representations for Instruction Following: A Semi-Supervised Language Interface to Control-->
<!--                </span>-->
<!--                <br>-->
<!--                <span id="author">-->
<!--                  Vivek Myers*,-->
<!--                  Andre He*,-->
<!--                  <span id="author-kuan">Kuan Fang</span>,-->
<!--                  Homer Walke, -->
<!--                  Philippe Hansen-Estruch, -->
<!--                  Ching-An Cheng, -->
<!--                  Mihai Jalobeanu,-->
<!--                  Andrey Kolobov,-->
<!--                  Anca Dragan, -->
<!--                  Sergey Levine-->
<!--                </span>-->
<!--                <br>-->
<!--                ArXiv Preprint-->
<!--                <br>-->
<!--                <a href="https://rail-berkeley.github.io/grif/paper.pdf">PDF</a> |-->
<!--                <a href="https://rail-berkeley.github.io/grif/">Website</a> |-->
<!--                <a href="https://github.com/rail-berkeley/grif_release">Code</a> |-->
<!--                <a href="https://kuanfang.github.io/bibtex/grif2023.bib">BibTex</a>-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->

<!--        </tbody></table>-->
<!--      </div>-->

<!--     论文-->
	    
      <div class="section">
        <h1>Publications</h1><br>
        <table id="publications">
          <tbody>

			  <tr>
            <td id="publications-image">
              <img src="./Quan Fang_files/MLMP.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Metapath-enhanced Language Model Pretraining on Text-Attributed Heterogeneous Graphs

                </span>
                <br>
                <span id="author">
					 Ji Dai,
                  <span id="author-kuan">Quan Fang*</span>,
                Jun Hu,
                 Desheng Cai
                </span>
                <br>
              ACM Transactions on Multimedia Computing, Communications and Applications  (<b>ACM TOMM</b>), 2026
                <br>
                <a href=" ">Paper</a> 
              </p>
            </td>
          </tr>

			  			  <tr>
            <td id="publications-image">
              <img src="./Quan Fang_files/NOTAM-Evolve.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  NOTAM-Evolve: A Knowledge-Guided Self-Evolving Optimization Framework with LLMs for NOTAM Interpretation

                </span>
                <br>
                <span id="author">
					 Maoqi Liu,
                  <span id="author-kuan">Quan Fang*</span>,
                YuhaoWu, 
			    Can Zhao, 
				Yang Yang, 
				Kaiquan Cai
                </span>
                <br>
             The 40th Annual AAAI Conference on Artificial Intelligence  (<b>AAAI</b>), 2026
                <br>
                <a href="https://arxiv.org/abs/2511.07982">Paper</a> 
              </p>
            </td>
          </tr>

			  			  <tr>
            <td id="publications-image">
              <img src="./Quan Fang_files/Knots.jpg">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                 Knots: A Large-Scale Multi-Agent Enhanced Expert-Annotated Dataset and LLM Prompt Optimization for NOTAM Semantic Parsing
                </span>
                <br>
                <span id="author">
					 Maoqi Liu,
                  <span id="author-kuan">Quan Fang*</span>,
				Yang Yang, 
                  Can Zhao, 
				Kaiquan Cai
                </span>
                <br>
              Advanced Engineering Informatics, 2025
                <br>
                <!-- <a href="https://dl.acm.org/doi/10.1145/3763241">Paper</a>  -->
              </p>
            </td>
          </tr>


			  <tr>
            <td id="publications-image">
              <img src="./Quan Fang_files/MLMP.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Metapath-enhanced Language Model Pretraining on Text-Attributed Heterogeneous Graphs

                </span>
                <br>
                <span id="author">
					 Shangheng Chen,
                  <span id="author-kuan">Quan Fang*</span>,
                Shengsheng Qian,
                  Changsheng Xu
                </span>
                <br>
              ACM Transactions on Multimedia Computing, Communications and Applications  (<b>ACM TOMM</b>), 2025
                <br>
                <a href="https://dl.acm.org/doi/10.1145/3763241">Paper</a> 
              </p>
            </td>
          </tr>
		  
		  <tr>
            <td id="publications-image">
              <img src="./Quan Fang_files/CMGNN.jpg">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Contrastive Multi-Modal Knowledge Graph Representation Learning
                </span>
                <br>
                <span id="author">
                  <span id="author-kuan">Quan Fang*</span>,
                 Xiaowei Zhang,
                  Jun Hu,
                  Xian Wu,
                  Changsheng Xu
                </span>
                <br>
               IEEE Transactions on Knowledge and Data Engineering  (<b>IEEE TKDE</b>), 2023
                <br>
                <a href="https://ieeexplore.ieee.org/document/9942333/">Paper</a> 
              </p>
            </td>
          </tr>

 <tr>
            <td id="publications-image">
              <img src="./Quan Fang_files/MedRec.jpg">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                 Knowledge-Enhanced Attributed Multi-Task Learning for Medicine Recommendation
                </span>
                <br>
                <span id="author">
		Yingying Zhang, 
		Xian Wu,
                <span id="author-kuan">Quan Fang</span>,
                  Shengsheng Qian, 
                  Changsheng Xu			
                </span>
                <br>
              ACM Transactions on Information Systems (<b>ACM TOIS</b>), 2023
                <br>
                <a href="https://dl.acm.org/doi/10.1145/3527662">Paper</a> 
<!--                <a href="https://sites.google.com/view/active-task-randomization">Website</a> |-->
<!--                <a href="https://kuanfang.github.io/bibtex/atr2022.bib">BibTex</a>-->
              </p>
            </td>
          </tr>
		  
 <tr>
            <td id="publications-image">
              <img src="./Quan Fang_files/TCKGE.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                     TCKGE: Transformers with contrastive learning for knowledge graph embedding             
		</span>
                <br>
                <span id="author">
		Xiaowei Zhang, 
                <span id="author-kuan">Quan Fang*</span>,
			Jun Hu,
                  Shengsheng Qian, 
                  Changsheng Xu			
                </span>
                <br>
             International Journal of Multimedia Information Retrieval (<b>IJMIR</b>), 2022
                <br>
                <a href="https://link.springer.com/article/10.1007/s13735-022-00256-3">Paper</a> 
              </p>
            </td>
          </tr>
		   <tr>
	        <td id="publications-image">
              <img src="./Quan Fang_files/cacm.jpg">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                    Heterogeneous Community Question Answering via Social-Aware Multi-Modal Co-Attention Convolutional Matching           
		</span>
                <br>
                <span id="author">
		Jun Hu, 
		Shengsheng Qian, 
                <span id="author-kuan">Quan Fang</span>,
                  Changsheng Xu			
                </span>
                <br>
             IEEE Transactions on Multimedia (<b>IEEE TMM</b>), 2021
                <br>
                <a href="https://ieeexplore.ieee.org/document/9142388/">Paper</a> 
              </p>
            </td>
          </tr>

			   <tr>
	        <td id="publications-image">
              <img src="./Quan Fang_files/KAWA.JPG">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                    Knowledge-aware Attentive Wasserstein Adversarial Dialogue Response Generation          
		</span>
                <br>
                <span id="author">
		Yingying Zhang,
                <span id="author-kuan">Quan Fang</span>,
			Shengsheng Qian,
                  Changsheng Xu			
                </span>
                <br>
            ACM Transactions on Intelligent Systems and Technology (<b>ACM TIST</b>), 2020
                <br>
                <a href="https://dl.acm.org/doi/10.1145/3384675">Paper</a> 
              </p>
            </td>
          </tr>

		  	   <tr>
	        <td id="publications-image">
              <img src="./Quan Fang_files/MMA.JPG">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                    Multi-modal Attentive Graph Pooling Model for Community Question Answer Matching           
		</span>
                <br>
                <span id="author">
		Jun Hu, 
                <span id="author-kuan">Quan Fang</span>,
		 Shengsheng Qian, 
                  Changsheng Xu			
                </span>
                <br>
            ACM  Multimedia (<b>ACM MM</b>), 2020
                <br>
                <a href="https://dl.acm.org/doi/10.1145/3394171.3413711">Paper</a> 
              </p>
            </td>
          </tr>

		  	  	   <tr>
	        <td id="publications-image">
              <img src="./Quan Fang_files/MMR.JPG">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                    Multi-modal Multi-relational Feature Aggregation Network for Medical Knowledge Representation Learning      
		</span>
                <br>
                <span id="author">
		Yingying Zhang, 
                <span id="author-kuan">Quan Fang</span>,
		 Shengsheng Qian, 
                  Changsheng Xu			
                </span>
                <br>
            ACM  Multimedia (<b>ACM MM</b>), 2020
                <br>
                <a href="https://dl.acm.org/doi/10.1145/3394171.3413711">Paper</a> 
              </p>
            </td>
          </tr>


        </tbody></table>
      </div>

      <div class="section">
        <h1>Awards and Honors</h1><br>

        <ul>
		 <li>北京市杰出青年基金获得者，2024</li>
	    <li>中国电子学会技术发明一等奖，2024</li>
       <li>2019年度中国多媒体大会最佳论文奖</li>
       <li>最佳论文提名，ACM Multimedia 2019</li>
       <li>2018年度中国多媒体大会多媒体前沿技术杰出展示奖</li>
       <li>2016年度中国科学院优秀博士学位论文</li>
		<li><a href="http://caai.cn/index.php?s=/Home/Article/detail/id/186.html"> 2016年度中国人工智能学会优秀博士学位论文 (Distinguished Dissertation Award, CAAI)</a></li>
		<li><a href="http://www.ccf.org.cn/sites/ccf/xhdtnry.jsp?contentId=2960910486969">Distinguished Dissertation Award Nominee</a>, China Computer Federation (CCF), 2016</li>
		<li>Pandeng Prize, CASIA, 2014</li>
		<li><a href="http://research.microsoft.com/en-us/collaboration/global/asia-pacific/talent/fellows.aspx"> Microsoft Research Asia Fellowship 2013</a></li>
		<li> National Ph.D. Scholarship, 2013</li>
      <li>Student Travel Grant, ACM Multimedia 2013</li>
      <li>Baidu Scholarship Finalist 2013</li>
      <li>Third Place, MSR-Bing Image Retrieval Challenge 2013 (Leader)</li>
		<li>Best Student Paper Award, International Conference on Multimedia Modeling (MMM
2013)</li>
		<li>2012-2013 Excellent Student, University of Chinese Academy of Sciences</li>
        </ul>
      </div>

	     <div class="section">
        <h1>Teaching</h1><br>

		 <ul>
		 <li>《大语言模型算法与实践》 </li>
		 <li>《知识图谱理论与应用》</li>
			 
		 </ul>
			 

        <ul>
<!--          <li>Teaching Assistant, <a href="http://web.stanford.edu/class/cs231a/">Computer Vision, From 3D Reconstruction to Recognition (CS231A)</a>, Stanford University, Winter 2021</li>-->
<!--          <li>Teaching Assistant, <a href="http://web.stanford.edu/class/cs231a/">Computer Vision, From 3D Reconstruction to Recognition (CS231A)</a>, Stanford University, Winter 2018</li>-->
<!--          <li>Instructor, <a href="https://ai4all.spcs.stanford.edu/">Stanford AI4ALL Program</a>, Stanford University, Summer 2020</li>-->
        </ul>
      </div>

 
		

      <div class="section">
        <h1>Professional Activities</h1><br>

        <ul>
         <li>Reviewer for TMM, TOMM, TNNLS, ...</li>
         <li>Reviewer for ACM Multimedia, AAAI, ...</li>
        </ul>
      </div>




    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
          <p align="left">
            <font size="2">
              <a href="https://people.eecs.berkeley.edu/~barron/">Website template courtesy</a>
            </font>
          </p>
        </td>
      </tr>
    </tbody></table>

    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MQ25LJL"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

	


</div></body></html>
